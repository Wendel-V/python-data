{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Abrindo arquivo -> Corpus Textual para o corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
      "\n",
      "java \n",
      "\n",
      "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
     ]
    }
   ],
   "source": [
    "with open(file = \"artigos.txt\", mode = \"r\", encoding = 'utf8' ) as f:\n",
    "    artigos = f.read()\n",
    "\n",
    "print(artigos[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2605046"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artigos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len('Olá')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto_exemplo = 'Ola, tudo bem?'\n",
    "tokens = texto_exemplo.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ola,', 'tudo', 'bem?']\n"
     ]
    }
   ],
   "source": [
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizamos o nltk para tokenizar o arquivo com mais eficiência"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Ola', ',', 'tudo', 'bem', '?']\n"
     ]
    }
   ],
   "source": [
    "palavras_separadas = nltk.tokenize.word_tokenize(texto_exemplo)\n",
    "\n",
    "print(palavras_separadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separando palavras de pontuações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'palavra'.isalpha()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separa_palavras(lista_tokens):\n",
    "    lista_palavras = []\n",
    "    for token in lista_tokens:\n",
    "        if token.isalpha():\n",
    "            lista_palavras.append(token)\n",
    "    return lista_palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Ola', 'tudo', 'bem']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "separa_palavras(palavras_separadas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aplicando ao Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_tokens = nltk.tokenize.word_tokenize(artigos)\n",
    "lista_palavras = separa_palavras(lista_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O número de palavras é 403106\n"
     ]
    }
   ],
   "source": [
    "print(f'O número de palavras é {len(lista_palavras)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'Temos', 'a', 'seguinte', 'classe']\n"
     ]
    }
   ],
   "source": [
    "print(lista_palavras[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalizando"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizacao(lista_palavras):\n",
    "    lista_normalizada = []\n",
    "    for palavra in lista_palavras:\n",
    "        lista_normalizada.append(palavra.lower())\n",
    "    return lista_normalizada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista_normalizada = normalizacao(lista_palavras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'temos', 'a', 'seguinte', 'classe']\n"
     ]
    }
   ],
   "source": [
    "print(lista_normalizada[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18465"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(lista_normalizada))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403106"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lista_normalizada)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando o corretor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('l', 'gica')"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista = 'lgica'\n",
    "\n",
    "(lista[:1], lista[1:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aqui criamos todas as possibilidades de uma determinada palavra digitada errada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['algica', 'blgica', 'clgica', 'dlgica', 'elgica', 'flgica', 'glgica', 'hlgica', 'ilgica', 'jlgica', 'klgica', 'llgica', 'mlgica', 'nlgica', 'olgica', 'plgica', 'qlgica', 'rlgica', 'slgica', 'tlgica', 'ulgica', 'vlgica', 'wlgica', 'xlgica', 'ylgica', 'zlgica', 'àlgica', 'álgica', 'âlgica', 'ãlgica', 'èlgica', 'élgica', 'êlgica', 'ìlgica', 'ílgica', 'îlgica', 'òlgica', 'ólgica', 'ôlgica', 'õlgica', 'ùlgica', 'úlgica', 'ûlgica', 'çlgica', 'lagica', 'lbgica', 'lcgica', 'ldgica', 'legica', 'lfgica', 'lggica', 'lhgica', 'ligica', 'ljgica', 'lkgica', 'llgica', 'lmgica', 'lngica', 'logica', 'lpgica', 'lqgica', 'lrgica', 'lsgica', 'ltgica', 'lugica', 'lvgica', 'lwgica', 'lxgica', 'lygica', 'lzgica', 'làgica', 'lágica', 'lâgica', 'lãgica', 'lègica', 'légica', 'lêgica', 'lìgica', 'lígica', 'lîgica', 'lògica', 'lógica', 'lôgica', 'lõgica', 'lùgica', 'lúgica', 'lûgica', 'lçgica', 'lgaica', 'lgbica', 'lgcica', 'lgdica', 'lgeica', 'lgfica', 'lggica', 'lghica', 'lgiica', 'lgjica', 'lgkica', 'lglica', 'lgmica', 'lgnica', 'lgoica', 'lgpica', 'lgqica', 'lgrica', 'lgsica', 'lgtica', 'lguica', 'lgvica', 'lgwica', 'lgxica', 'lgyica', 'lgzica', 'lgàica', 'lgáica', 'lgâica', 'lgãica', 'lgèica', 'lgéica', 'lgêica', 'lgìica', 'lgíica', 'lgîica', 'lgòica', 'lgóica', 'lgôica', 'lgõica', 'lgùica', 'lgúica', 'lgûica', 'lgçica', 'lgiaca', 'lgibca', 'lgicca', 'lgidca', 'lgieca', 'lgifca', 'lgigca', 'lgihca', 'lgiica', 'lgijca', 'lgikca', 'lgilca', 'lgimca', 'lginca', 'lgioca', 'lgipca', 'lgiqca', 'lgirca', 'lgisca', 'lgitca', 'lgiuca', 'lgivca', 'lgiwca', 'lgixca', 'lgiyca', 'lgizca', 'lgiàca', 'lgiáca', 'lgiâca', 'lgiãca', 'lgièca', 'lgiéca', 'lgiêca', 'lgiìca', 'lgiíca', 'lgiîca', 'lgiòca', 'lgióca', 'lgiôca', 'lgiõca', 'lgiùca', 'lgiúca', 'lgiûca', 'lgiçca', 'lgicaa', 'lgicba', 'lgicca', 'lgicda', 'lgicea', 'lgicfa', 'lgicga', 'lgicha', 'lgicia', 'lgicja', 'lgicka', 'lgicla', 'lgicma', 'lgicna', 'lgicoa', 'lgicpa', 'lgicqa', 'lgicra', 'lgicsa', 'lgicta', 'lgicua', 'lgicva', 'lgicwa', 'lgicxa', 'lgicya', 'lgicza', 'lgicàa', 'lgicáa', 'lgicâa', 'lgicãa', 'lgicèa', 'lgicéa', 'lgicêa', 'lgicìa', 'lgicía', 'lgicîa', 'lgicòa', 'lgicóa', 'lgicôa', 'lgicõa', 'lgicùa', 'lgicúa', 'lgicûa', 'lgicça', 'lgicaa', 'lgicab', 'lgicac', 'lgicad', 'lgicae', 'lgicaf', 'lgicag', 'lgicah', 'lgicai', 'lgicaj', 'lgicak', 'lgical', 'lgicam', 'lgican', 'lgicao', 'lgicap', 'lgicaq', 'lgicar', 'lgicas', 'lgicat', 'lgicau', 'lgicav', 'lgicaw', 'lgicax', 'lgicay', 'lgicaz', 'lgicaà', 'lgicaá', 'lgicaâ', 'lgicaã', 'lgicaè', 'lgicaé', 'lgicaê', 'lgicaì', 'lgicaí', 'lgicaî', 'lgicaò', 'lgicaó', 'lgicaô', 'lgicaõ', 'lgicaù', 'lgicaú', 'lgicaû', 'lgicaç']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "palavra_exemplo = 'lgica'\n",
    "\n",
    "def insere_letras(fatias):   \n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'   \n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)      \n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Aqui criamos o corretor, que definira qual é a palavra correta na lista de palavras possível, escolhendo a que aparece com mais frequencia no nosso corpus textual (texto base)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavra_correta = max(palavras_geradas, key = probabilidade)\n",
    "    return palavra_correta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('de', 15502),\n",
       " ('o', 14056),\n",
       " ('que', 12230),\n",
       " ('a', 11099),\n",
       " ('e', 10501),\n",
       " ('para', 7710),\n",
       " ('um', 6368),\n",
       " ('é', 5899),\n",
       " ('uma', 5220),\n",
       " ('do', 5124)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frequencia = nltk.FreqDist(lista_normalizada)\n",
    "total_palavras = len(lista_normalizada)\n",
    "frequencia.most_common(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def probabilidade(palavra_gerada):\n",
    "    return frequencia[palavra_gerada]/total_palavras\n",
    "\n",
    "probabilidade('lagica')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corretor('lógic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('podemos', 'pyodemos'),\n",
       " ('esse', 'esje'),\n",
       " ('já', 'jrá'),\n",
       " ('nosso', 'nossov'),\n",
       " ('são', 'sãêo'),\n",
       " ('dos', 'dosa'),\n",
       " ('muito', 'muifo'),\n",
       " ('imagem', 'iômagem'),\n",
       " ('sua', 'ósua'),\n",
       " ('também', 'tambéùm')]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def cria_dados_teste(nome_arquivo):\n",
    "    lista_palavras_teste = []\n",
    "    f = open(nome_arquivo, \"r\", encoding = 'utf-8')\n",
    "    for linha in f:\n",
    "        separada = linha.split() #se fosse no colab, poderia fazer correta, errada = linha.split() direto.\n",
    "        correta = separada[0]    #Fiz essa gambiarra pra rodar aqui no jupyter\n",
    "        errada = separada[1]\n",
    "        lista_palavras_teste.append((correta, errada))\n",
    "    f.close()\n",
    "    return lista_palavras_teste\n",
    "\n",
    "lista_teste = cria_dados_teste('palavras.txt')\n",
    "\n",
    "lista_teste[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.08 % de 186 palavras\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_acerto = round((acertou/numero_palavras)*100, 2)\n",
    "    print(f'{taxa_acerto} % de {numero_palavras} palavras')\n",
    "\n",
    "\n",
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cobrindo outros casos de erro de digitação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])      \n",
    "    return novas_palavras\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alóigica', 'blóigica', 'clóigica', 'dlóigica', 'elóigica', 'flóigica', 'glóigica', 'hlóigica', 'ilóigica', 'jlóigica', 'klóigica', 'llóigica', 'mlóigica', 'nlóigica', 'olóigica', 'plóigica', 'qlóigica', 'rlóigica', 'slóigica', 'tlóigica', 'ulóigica', 'vlóigica', 'wlóigica', 'xlóigica', 'ylóigica', 'zlóigica', 'àlóigica', 'álóigica', 'âlóigica', 'ãlóigica', 'èlóigica', 'élóigica', 'êlóigica', 'ìlóigica', 'ílóigica', 'îlóigica', 'òlóigica', 'ólóigica', 'ôlóigica', 'õlóigica', 'ùlóigica', 'úlóigica', 'ûlóigica', 'çlóigica', 'laóigica', 'lbóigica', 'lcóigica', 'ldóigica', 'leóigica', 'lfóigica', 'lgóigica', 'lhóigica', 'lióigica', 'ljóigica', 'lkóigica', 'llóigica', 'lmóigica', 'lnóigica', 'loóigica', 'lpóigica', 'lqóigica', 'lróigica', 'lsóigica', 'ltóigica', 'luóigica', 'lvóigica', 'lwóigica', 'lxóigica', 'lyóigica', 'lzóigica', 'làóigica', 'láóigica', 'lâóigica', 'lãóigica', 'lèóigica', 'léóigica', 'lêóigica', 'lìóigica', 'líóigica', 'lîóigica', 'lòóigica', 'lóóigica', 'lôóigica', 'lõóigica', 'lùóigica', 'lúóigica', 'lûóigica', 'lçóigica', 'lóaigica', 'lóbigica', 'lócigica', 'lódigica', 'lóeigica', 'lófigica', 'lógigica', 'lóhigica', 'lóiigica', 'lójigica', 'lókigica', 'lóligica', 'lómigica', 'lónigica', 'lóoigica', 'lópigica', 'lóqigica', 'lórigica', 'lósigica', 'lótigica', 'lóuigica', 'lóvigica', 'lówigica', 'lóxigica', 'lóyigica', 'lózigica', 'lóàigica', 'lóáigica', 'lóâigica', 'lóãigica', 'lóèigica', 'lóéigica', 'lóêigica', 'lóìigica', 'lóíigica', 'lóîigica', 'lóòigica', 'lóóigica', 'lóôigica', 'lóõigica', 'lóùigica', 'lóúigica', 'lóûigica', 'lóçigica', 'lóiagica', 'lóibgica', 'lóicgica', 'lóidgica', 'lóiegica', 'lóifgica', 'lóiggica', 'lóihgica', 'lóiigica', 'lóijgica', 'lóikgica', 'lóilgica', 'lóimgica', 'lóingica', 'lóiogica', 'lóipgica', 'lóiqgica', 'lóirgica', 'lóisgica', 'lóitgica', 'lóiugica', 'lóivgica', 'lóiwgica', 'lóixgica', 'lóiygica', 'lóizgica', 'lóiàgica', 'lóiágica', 'lóiâgica', 'lóiãgica', 'lóiègica', 'lóiégica', 'lóiêgica', 'lóiìgica', 'lóiígica', 'lóiîgica', 'lóiògica', 'lóiógica', 'lóiôgica', 'lóiõgica', 'lóiùgica', 'lóiúgica', 'lóiûgica', 'lóiçgica', 'lóigaica', 'lóigbica', 'lóigcica', 'lóigdica', 'lóigeica', 'lóigfica', 'lóiggica', 'lóighica', 'lóigiica', 'lóigjica', 'lóigkica', 'lóiglica', 'lóigmica', 'lóignica', 'lóigoica', 'lóigpica', 'lóigqica', 'lóigrica', 'lóigsica', 'lóigtica', 'lóiguica', 'lóigvica', 'lóigwica', 'lóigxica', 'lóigyica', 'lóigzica', 'lóigàica', 'lóigáica', 'lóigâica', 'lóigãica', 'lóigèica', 'lóigéica', 'lóigêica', 'lóigìica', 'lóigíica', 'lóigîica', 'lóigòica', 'lóigóica', 'lóigôica', 'lóigõica', 'lóigùica', 'lóigúica', 'lóigûica', 'lóigçica', 'lóigiaca', 'lóigibca', 'lóigicca', 'lóigidca', 'lóigieca', 'lóigifca', 'lóigigca', 'lóigihca', 'lóigiica', 'lóigijca', 'lóigikca', 'lóigilca', 'lóigimca', 'lóiginca', 'lóigioca', 'lóigipca', 'lóigiqca', 'lóigirca', 'lóigisca', 'lóigitca', 'lóigiuca', 'lóigivca', 'lóigiwca', 'lóigixca', 'lóigiyca', 'lóigizca', 'lóigiàca', 'lóigiáca', 'lóigiâca', 'lóigiãca', 'lóigièca', 'lóigiéca', 'lóigiêca', 'lóigiìca', 'lóigiíca', 'lóigiîca', 'lóigiòca', 'lóigióca', 'lóigiôca', 'lóigiõca', 'lóigiùca', 'lóigiúca', 'lóigiûca', 'lóigiçca', 'lóigicaa', 'lóigicba', 'lóigicca', 'lóigicda', 'lóigicea', 'lóigicfa', 'lóigicga', 'lóigicha', 'lóigicia', 'lóigicja', 'lóigicka', 'lóigicla', 'lóigicma', 'lóigicna', 'lóigicoa', 'lóigicpa', 'lóigicqa', 'lóigicra', 'lóigicsa', 'lóigicta', 'lóigicua', 'lóigicva', 'lóigicwa', 'lóigicxa', 'lóigicya', 'lóigicza', 'lóigicàa', 'lóigicáa', 'lóigicâa', 'lóigicãa', 'lóigicèa', 'lóigicéa', 'lóigicêa', 'lóigicìa', 'lóigicía', 'lóigicîa', 'lóigicòa', 'lóigicóa', 'lóigicôa', 'lóigicõa', 'lóigicùa', 'lóigicúa', 'lóigicûa', 'lóigicça', 'lóigicaa', 'lóigicab', 'lóigicac', 'lóigicad', 'lóigicae', 'lóigicaf', 'lóigicag', 'lóigicah', 'lóigicai', 'lóigicaj', 'lóigicak', 'lóigical', 'lóigicam', 'lóigican', 'lóigicao', 'lóigicap', 'lóigicaq', 'lóigicar', 'lóigicas', 'lóigicat', 'lóigicau', 'lóigicav', 'lóigicaw', 'lóigicax', 'lóigicay', 'lóigicaz', 'lóigicaà', 'lóigicaá', 'lóigicaâ', 'lóigicaã', 'lóigicaè', 'lóigicaé', 'lóigicaê', 'lóigicaì', 'lóigicaí', 'lóigicaî', 'lóigicaò', 'lóigicaó', 'lóigicaô', 'lóigicaõ', 'lóigicaù', 'lóigicaú', 'lóigicaû', 'lóigicaç', 'óigica', 'ligica', 'lógica', 'lóiica', 'lóigca', 'lóigia', 'lóigic', 'lóigica']\n"
     ]
    }
   ],
   "source": [
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    return palavras_geradas\n",
    "\n",
    "palavra_exemplo = 'lóigica'\n",
    "\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.4 % de 186 palavras\n"
     ]
    }
   ],
   "source": [
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deletando_caracteres(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        novas_palavras.append(E + D[1:])      \n",
    "    return novas_palavras\n",
    "    \n",
    "def insere_letras(fatias):   \n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'   \n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D)      \n",
    "    return novas_palavras\n",
    "\n",
    "def troca_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    letras = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'   \n",
    "    for E, D in fatias:\n",
    "        for letra in letras:\n",
    "            novas_palavras.append(E + letra + D[1:])      \n",
    "    return novas_palavras\n",
    "\n",
    "def inverte_letra(fatias):\n",
    "    novas_palavras = []\n",
    "    for E, D in fatias:\n",
    "        if len(D) > 1:\n",
    "            novas_palavras.append(E + D[1] + D[0] + D[2:])      \n",
    "    return novas_palavras\n",
    "\n",
    "def gerador_palavras(palavra):\n",
    "    fatias = []\n",
    "    for i in range(len(palavra) + 1):\n",
    "        fatias.append((palavra[:i], palavra[i:]))\n",
    "    palavras_geradas = insere_letras(fatias)\n",
    "    palavras_geradas += deletando_caracteres(fatias)\n",
    "    palavras_geradas += troca_letra(fatias)\n",
    "    palavras_geradas += inverte_letra(fatias)\n",
    "    return palavras_geradas\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alógiac', 'blógiac', 'clógiac', 'dlógiac', 'elógiac', 'flógiac', 'glógiac', 'hlógiac', 'ilógiac', 'jlógiac', 'klógiac', 'llógiac', 'mlógiac', 'nlógiac', 'ológiac', 'plógiac', 'qlógiac', 'rlógiac', 'slógiac', 'tlógiac', 'ulógiac', 'vlógiac', 'wlógiac', 'xlógiac', 'ylógiac', 'zlógiac', 'àlógiac', 'álógiac', 'âlógiac', 'ãlógiac', 'èlógiac', 'élógiac', 'êlógiac', 'ìlógiac', 'ílógiac', 'îlógiac', 'òlógiac', 'ólógiac', 'ôlógiac', 'õlógiac', 'ùlógiac', 'úlógiac', 'ûlógiac', 'çlógiac', 'laógiac', 'lbógiac', 'lcógiac', 'ldógiac', 'leógiac', 'lfógiac', 'lgógiac', 'lhógiac', 'liógiac', 'ljógiac', 'lkógiac', 'llógiac', 'lmógiac', 'lnógiac', 'loógiac', 'lpógiac', 'lqógiac', 'lrógiac', 'lsógiac', 'ltógiac', 'luógiac', 'lvógiac', 'lwógiac', 'lxógiac', 'lyógiac', 'lzógiac', 'làógiac', 'láógiac', 'lâógiac', 'lãógiac', 'lèógiac', 'léógiac', 'lêógiac', 'lìógiac', 'líógiac', 'lîógiac', 'lòógiac', 'lóógiac', 'lôógiac', 'lõógiac', 'lùógiac', 'lúógiac', 'lûógiac', 'lçógiac', 'lóagiac', 'lóbgiac', 'lócgiac', 'lódgiac', 'lóegiac', 'lófgiac', 'lóggiac', 'lóhgiac', 'lóigiac', 'lójgiac', 'lókgiac', 'lólgiac', 'lómgiac', 'lóngiac', 'lóogiac', 'lópgiac', 'lóqgiac', 'lórgiac', 'lósgiac', 'lótgiac', 'lóugiac', 'lóvgiac', 'lówgiac', 'lóxgiac', 'lóygiac', 'lózgiac', 'lóàgiac', 'lóágiac', 'lóâgiac', 'lóãgiac', 'lóègiac', 'lóégiac', 'lóêgiac', 'lóìgiac', 'lóígiac', 'lóîgiac', 'lóògiac', 'lóógiac', 'lóôgiac', 'lóõgiac', 'lóùgiac', 'lóúgiac', 'lóûgiac', 'lóçgiac', 'lógaiac', 'lógbiac', 'lógciac', 'lógdiac', 'lógeiac', 'lógfiac', 'lóggiac', 'lóghiac', 'lógiiac', 'lógjiac', 'lógkiac', 'lógliac', 'lógmiac', 'lógniac', 'lógoiac', 'lógpiac', 'lógqiac', 'lógriac', 'lógsiac', 'lógtiac', 'lóguiac', 'lógviac', 'lógwiac', 'lógxiac', 'lógyiac', 'lógziac', 'lógàiac', 'lógáiac', 'lógâiac', 'lógãiac', 'lógèiac', 'lógéiac', 'lógêiac', 'lógìiac', 'lógíiac', 'lógîiac', 'lógòiac', 'lógóiac', 'lógôiac', 'lógõiac', 'lógùiac', 'lógúiac', 'lógûiac', 'lógçiac', 'lógiaac', 'lógibac', 'lógicac', 'lógidac', 'lógieac', 'lógifac', 'lógigac', 'lógihac', 'lógiiac', 'lógijac', 'lógikac', 'lógilac', 'lógimac', 'lóginac', 'lógioac', 'lógipac', 'lógiqac', 'lógirac', 'lógisac', 'lógitac', 'lógiuac', 'lógivac', 'lógiwac', 'lógixac', 'lógiyac', 'lógizac', 'lógiàac', 'lógiáac', 'lógiâac', 'lógiãac', 'lógièac', 'lógiéac', 'lógiêac', 'lógiìac', 'lógiíac', 'lógiîac', 'lógiòac', 'lógióac', 'lógiôac', 'lógiõac', 'lógiùac', 'lógiúac', 'lógiûac', 'lógiçac', 'lógiaac', 'lógiabc', 'lógiacc', 'lógiadc', 'lógiaec', 'lógiafc', 'lógiagc', 'lógiahc', 'lógiaic', 'lógiajc', 'lógiakc', 'lógialc', 'lógiamc', 'lógianc', 'lógiaoc', 'lógiapc', 'lógiaqc', 'lógiarc', 'lógiasc', 'lógiatc', 'lógiauc', 'lógiavc', 'lógiawc', 'lógiaxc', 'lógiayc', 'lógiazc', 'lógiaàc', 'lógiaác', 'lógiaâc', 'lógiaãc', 'lógiaèc', 'lógiaéc', 'lógiaêc', 'lógiaìc', 'lógiaíc', 'lógiaîc', 'lógiaòc', 'lógiaóc', 'lógiaôc', 'lógiaõc', 'lógiaùc', 'lógiaúc', 'lógiaûc', 'lógiaçc', 'lógiaca', 'lógiacb', 'lógiacc', 'lógiacd', 'lógiace', 'lógiacf', 'lógiacg', 'lógiach', 'lógiaci', 'lógiacj', 'lógiack', 'lógiacl', 'lógiacm', 'lógiacn', 'lógiaco', 'lógiacp', 'lógiacq', 'lógiacr', 'lógiacs', 'lógiact', 'lógiacu', 'lógiacv', 'lógiacw', 'lógiacx', 'lógiacy', 'lógiacz', 'lógiacà', 'lógiacá', 'lógiacâ', 'lógiacã', 'lógiacè', 'lógiacé', 'lógiacê', 'lógiacì', 'lógiací', 'lógiacî', 'lógiacò', 'lógiacó', 'lógiacô', 'lógiacõ', 'lógiacù', 'lógiacú', 'lógiacû', 'lógiacç', 'ógiac', 'lgiac', 'lóiac', 'lógac', 'lógic', 'lógia', 'lógiac', 'aógiac', 'bógiac', 'cógiac', 'dógiac', 'eógiac', 'fógiac', 'gógiac', 'hógiac', 'iógiac', 'jógiac', 'kógiac', 'lógiac', 'mógiac', 'nógiac', 'oógiac', 'pógiac', 'qógiac', 'rógiac', 'sógiac', 'tógiac', 'uógiac', 'vógiac', 'wógiac', 'xógiac', 'yógiac', 'zógiac', 'àógiac', 'áógiac', 'âógiac', 'ãógiac', 'èógiac', 'éógiac', 'êógiac', 'ìógiac', 'íógiac', 'îógiac', 'òógiac', 'óógiac', 'ôógiac', 'õógiac', 'ùógiac', 'úógiac', 'ûógiac', 'çógiac', 'lagiac', 'lbgiac', 'lcgiac', 'ldgiac', 'legiac', 'lfgiac', 'lggiac', 'lhgiac', 'ligiac', 'ljgiac', 'lkgiac', 'llgiac', 'lmgiac', 'lngiac', 'logiac', 'lpgiac', 'lqgiac', 'lrgiac', 'lsgiac', 'ltgiac', 'lugiac', 'lvgiac', 'lwgiac', 'lxgiac', 'lygiac', 'lzgiac', 'làgiac', 'lágiac', 'lâgiac', 'lãgiac', 'lègiac', 'légiac', 'lêgiac', 'lìgiac', 'lígiac', 'lîgiac', 'lògiac', 'lógiac', 'lôgiac', 'lõgiac', 'lùgiac', 'lúgiac', 'lûgiac', 'lçgiac', 'lóaiac', 'lóbiac', 'lóciac', 'lódiac', 'lóeiac', 'lófiac', 'lógiac', 'lóhiac', 'lóiiac', 'lójiac', 'lókiac', 'lóliac', 'lómiac', 'lóniac', 'lóoiac', 'lópiac', 'lóqiac', 'lóriac', 'lósiac', 'lótiac', 'lóuiac', 'lóviac', 'lówiac', 'lóxiac', 'lóyiac', 'lóziac', 'lóàiac', 'lóáiac', 'lóâiac', 'lóãiac', 'lóèiac', 'lóéiac', 'lóêiac', 'lóìiac', 'lóíiac', 'lóîiac', 'lóòiac', 'lóóiac', 'lóôiac', 'lóõiac', 'lóùiac', 'lóúiac', 'lóûiac', 'lóçiac', 'lógaac', 'lógbac', 'lógcac', 'lógdac', 'lógeac', 'lógfac', 'lóggac', 'lóghac', 'lógiac', 'lógjac', 'lógkac', 'lóglac', 'lógmac', 'lógnac', 'lógoac', 'lógpac', 'lógqac', 'lógrac', 'lógsac', 'lógtac', 'lóguac', 'lógvac', 'lógwac', 'lógxac', 'lógyac', 'lógzac', 'lógàac', 'lógáac', 'lógâac', 'lógãac', 'lógèac', 'lógéac', 'lógêac', 'lógìac', 'lógíac', 'lógîac', 'lógòac', 'lógóac', 'lógôac', 'lógõac', 'lógùac', 'lógúac', 'lógûac', 'lógçac', 'lógiac', 'lógibc', 'lógicc', 'lógidc', 'lógiec', 'lógifc', 'lógigc', 'lógihc', 'lógiic', 'lógijc', 'lógikc', 'lógilc', 'lógimc', 'lóginc', 'lógioc', 'lógipc', 'lógiqc', 'lógirc', 'lógisc', 'lógitc', 'lógiuc', 'lógivc', 'lógiwc', 'lógixc', 'lógiyc', 'lógizc', 'lógiàc', 'lógiác', 'lógiâc', 'lógiãc', 'lógièc', 'lógiéc', 'lógiêc', 'lógiìc', 'lógiíc', 'lógiîc', 'lógiòc', 'lógióc', 'lógiôc', 'lógiõc', 'lógiùc', 'lógiúc', 'lógiûc', 'lógiçc', 'lógiaa', 'lógiab', 'lógiac', 'lógiad', 'lógiae', 'lógiaf', 'lógiag', 'lógiah', 'lógiai', 'lógiaj', 'lógiak', 'lógial', 'lógiam', 'lógian', 'lógiao', 'lógiap', 'lógiaq', 'lógiar', 'lógias', 'lógiat', 'lógiau', 'lógiav', 'lógiaw', 'lógiax', 'lógiay', 'lógiaz', 'lógiaà', 'lógiaá', 'lógiaâ', 'lógiaã', 'lógiaè', 'lógiaé', 'lógiaê', 'lógiaì', 'lógiaí', 'lógiaî', 'lógiaò', 'lógiaó', 'lógiaô', 'lógiaõ', 'lógiaù', 'lógiaú', 'lógiaû', 'lógiaç', 'lógiaca', 'lógiacb', 'lógiacc', 'lógiacd', 'lógiace', 'lógiacf', 'lógiacg', 'lógiach', 'lógiaci', 'lógiacj', 'lógiack', 'lógiacl', 'lógiacm', 'lógiacn', 'lógiaco', 'lógiacp', 'lógiacq', 'lógiacr', 'lógiacs', 'lógiact', 'lógiacu', 'lógiacv', 'lógiacw', 'lógiacx', 'lógiacy', 'lógiacz', 'lógiacà', 'lógiacá', 'lógiacâ', 'lógiacã', 'lógiacè', 'lógiacé', 'lógiacê', 'lógiacì', 'lógiací', 'lógiacî', 'lógiacò', 'lógiacó', 'lógiacô', 'lógiacõ', 'lógiacù', 'lógiacú', 'lógiacû', 'lógiacç', 'ólgiac', 'lgóiac', 'lóigac', 'lógaic', 'lógica']\n"
     ]
    }
   ],
   "source": [
    "palavra_exemplo = 'lógiac'\n",
    "\n",
    "palavras_geradas = gerador_palavras(palavra_exemplo)\n",
    "print(palavras_geradas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34 % de 186 palavras\n"
     ]
    }
   ],
   "source": [
    "avaliador(lista_teste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34 % de 186 palavras, desconhecida é 6.99 %\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "        else:\n",
    "            desconhecida += (correta not in vocabulario)\n",
    "    taxa_acerto = round((acertou/numero_palavras)*100, 2)\n",
    "    taxa_desconhecida = round((desconhecida/numero_palavras)*100, 2)\n",
    "    print(f'{taxa_acerto} % de {numero_palavras} palavras, desconhecida é {taxa_desconhecida} %')\n",
    "\n",
    "    \n",
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "palavra = 'lóiigica'\n",
    "\n",
    "def gerador_turbinado(palavras_geradas):\n",
    "    novas_palavras = []\n",
    "    for palavra in palavras_geradas:\n",
    "        novas_palavras += gerador_palavras(palavra)\n",
    "    return novas_palavras\n",
    "\n",
    "\n",
    "palavras_g = gerador_turbinado(gerador_palavras(palavra))\n",
    "\n",
    "'lógica' in palavras_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " def novo_corretor(palavra):\n",
    "    palavras_geradas = gerador_palavras(palavra)\n",
    "    palavras_turbinado = gerador_turbinado(palavras_geradas)\n",
    "    todas_palavras = set(palavras_geradas + palavras_turbinado)\n",
    "    candidatos = [palavra]\n",
    "\n",
    "    for palavra in todas_palavras:\n",
    "        if palavra in vocabulario:\n",
    "            candidatos.append(palavra)\n",
    "    \n",
    "    palavra_correta = max(candidatos, key = probabilidade)\n",
    "    return palavra_correta\n",
    "\n",
    "novo_corretor(palavra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "esje-esse-se\n",
      "sãêo-são-não\n",
      "dosa-dos-do\n",
      "eme-em-de\n",
      "eàssa-essa-esse\n",
      "daõs-das-da\n",
      "céda-cada-da\n",
      "noâ-no-o\n",
      "enêão-então-não\n",
      "tĩem-tem-em\n",
      "nossah-nossa-nosso\n",
      "teb-tem-de\n",
      "atĩ-até-a\n",
      "âem-em-de\n",
      "foo-foi-o\n",
      "serr-ser-se\n",
      "entke-entre-então\n",
      "van-vai-a\n",
      "çeus-seus-seu\n",
      "eû-e-de\n",
      "temeo-tempo-temos\n",
      "semre-sempre-ser\n",
      "elaá-ela-ele\n",
      "síó-só-se\n",
      "siàe-site-se\n",
      "seém-sem-em\n",
      "peln-pelo-ele\n",
      "aléra-alura-agora\n",
      "tdia-dia-da\n",
      "tuúo-tudo-tipo\n",
      "jé-é-de\n",
      "sãô-são-não\n",
      "odos-dos-do\n",
      "siua-sua-seu\n",
      "elpe-ele-esse\n",
      "teos-temos-os\n",
      "eũsa-essa-esse\n",
      "vjmos-vamos-temos\n",
      "dms-dos-de\n",
      "cava-java-para\n",
      "ános-nos-no\n",
      "èaso-caso-as\n",
      "túem-tem-em\n",
      "daáos-dados-dos\n",
      "nossk-nosso-nosso\n",
      "tãer-ter-ser\n",
      "vté-até-é\n",
      "búm-bem-um\n",
      "sçerá-será-ser\n",
      "entró-entre-então\n",
      "uai-vai-a\n",
      "sâus-seus-seu\n",
      "ìeu-seu-de\n",
      "fual-qual-sua\n",
      "elal-ela-ele\n",
      "skó-só-se\n",
      "secm-sem-em\n",
      "aluéa-alura-além\n",
      "dil-dia-de\n",
      "sód-só-se\n",
      "eúaa-aeúaa-essa\n",
      "ró-só-de\n",
      "dĩaz-adĩaz-da\n",
      "correptor-corretor-correto\n",
      "trtica-tática-prática\n",
      "ewpoderamento-aewpoderamento-ewpoderamento\n",
      "îgato-gato-fato\n",
      "cakvalo-acakvalo-carvalho\n",
      "canelac-acanelac-janela\n",
      "tênisy-atênisy-tênisy\n",
      "anciosa-aanciosa-ansioso\n",
      "ancciosa-aancciosa-ancciosa\n",
      "ansioa-aansioa-antiga\n",
      "asterístico-aasterístico-asterístico\n",
      "entertido-aentertido-entendido\n",
      "ritimo-ritmo-ótimo\n",
      "indiota-aindiota-indica\n",
      "tomare-tomar-tomar\n",
      "seje-seja-se\n",
      "provalecer-aprovalecer-prevaleceu\n",
      "esteje-esteja-este\n",
      "mindigo-amindigo-indico\n",
      "pertubar-apertubar-derrubar\n",
      "55.38 % de 186 palavras, desconhecida é 6.99 %\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = novo_corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "        else:\n",
    "            print(errada + '-' + corretor(errada) + '-' + palavra_corrigida)\n",
    "    taxa_acerto = round((acertou/numero_palavras)*100, 2)\n",
    "    taxa_desconhecida = round((desconhecida/numero_palavras)*100, 2)\n",
    "    print(f'{taxa_acerto} % de {numero_palavras} palavras, desconhecida é {taxa_desconhecida} %')\n",
    "\n",
    "    \n",
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34 % de 186 palavras, desconhecida é 6.99 %\n"
     ]
    }
   ],
   "source": [
    "def avaliador(testes, vocabulario):\n",
    "    numero_palavras = len(testes)\n",
    "    acertou = 0\n",
    "    desconhecida = 0\n",
    "    for correta, errada in testes:\n",
    "        palavra_corrigida = corretor(errada)\n",
    "        desconhecida += (correta not in vocabulario)\n",
    "        if palavra_corrigida == correta:\n",
    "            acertou += 1\n",
    "    taxa_acerto = round((acertou/numero_palavras)*100, 2)\n",
    "    taxa_desconhecida = round((desconhecida/numero_palavras)*100, 2)\n",
    "    print(f'{taxa_acerto} % de {numero_palavras} palavras, desconhecida é {taxa_desconhecida} %')\n",
    "\n",
    "    \n",
    "vocabulario = set(lista_normalizada)\n",
    "avaliador(lista_teste, vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Avaliando ambos os corretores, podemos chegar a conclusão de que o antigo performou muito melhor para esse conjunto de palavras de teste e, sendo assim, faz mais sentido utilizá-lo ao invés do 'novo_corretor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pode\n",
      "poder\n"
     ]
    }
   ],
   "source": [
    "palavra = 'podeer'\n",
    "\n",
    "print(novo_corretor(palavra))\n",
    "print(corretor(palavra))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### No entanto, existem palavras erradas em que o novo corretor performa muito melhor, sobretudo para casos em que há letras equivocadas que se repetem duas vezes dentro da mesma palavra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
